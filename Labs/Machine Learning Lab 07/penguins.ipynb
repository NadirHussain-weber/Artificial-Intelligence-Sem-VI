{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset file\n",
    "dataset = pd.read_csv(\"penguins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      ".           1\n",
      "FEMALE    165\n",
      "MALE      168\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if the dataset instances are properly distributed\n",
    "print(dataset.groupby('sex').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is not equal. I.e there are 165 Female species and 168 male species. While 1 has no gender\n",
    "#We convert the to female that has no gender\n",
    "dataset['sex'] = dataset['sex'].replace(['.'],'FEMALE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "Adelie       152\n",
      "Chinstrap     68\n",
      "Gentoo       124\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now we have just 2 genders. Male and Female. But not equal number of records. We remove 2 male species\n",
    "print(dataset.groupby('species').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "FEMALE    166\n",
      "MALE      168\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Drop records where sex value is null\n",
    "dataset=dataset.dropna(subset=[\"sex\"]) #In data, if sex=NA is removed, then no null column is left\n",
    "# Now again see the number of records\n",
    "print(dataset.groupby('sex').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species              False\n",
       "island               False\n",
       "culmen_length_mm     False\n",
       "culmen_depth_mm      False\n",
       "flipper_length_mm    False\n",
       "body_mass_g          False\n",
       "sex                  False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(20)\n",
    "#No attribute is Null\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input (X) and output_labels (Y) vectors\n",
    "feature_columns = ['culmen_length_mm','culmen_depth_mm','flipper_length_mm','body_mass_g']\n",
    "#culmen_length_mm\tculmen_depth_mm\tflipper_length_mm\tbody_mass_g\n",
    "\n",
    "X = dataset[feature_columns].values\n",
    "y = dataset['species'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply numerical encoding to convert alphabetical names\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset in testing and training vectors for cross-validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate learning model (k = 3)\n",
    "classifier = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "#classifier = LinearDiscriminantAnalysis()\n",
    "#classifier = DecisionTreeClassifier()\n",
    "#classifier = SVC(gamma = 'auto')\n",
    "#classifier = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  1  3]\n",
      " [13  5  0]\n",
      " [ 4  0 29]]\n"
     ]
    }
   ],
   "source": [
    "# Create and view the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is equal 79.21 %.\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print('Accuracy of our model is equal ' + str(round(accuracy, 2)) + ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we classify the penguins with 20% data for testing and 80% for training and keeping n=3 by following attributes,\n",
    "#then accuracy for each tril is\n",
    "\n",
    "#culmen_length_mm=76.12%\n",
    "#culmen_depth_mm=79.1%\n",
    "#flipper_length_mm=79.1%\n",
    "#body_mass_g=73.13%\n",
    "'''\n",
    "CL+CD=97.01%\n",
    "CL+FL=97.01%\n",
    "CL+BM=80.6%\n",
    "CD+FL=83.58%\n",
    "CD+BM=70.15%\n",
    "FL+BM=76.12%\n",
    "CL+CD+FL=97.01%\n",
    "CL+CD+BM=82.09%\n",
    "CL+FL+BM=82.09%\n",
    "CD+FL+BM=76.12%\n",
    "CL+CD+FL+BM=83.58%\n",
    "'''\n",
    "#Where \n",
    "'''\n",
    "CL=cumen_length_mm\n",
    "CD=cumen_depth_mm\n",
    "FL=flipper_length_mm\n",
    "BM=body_mass_g\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we classify the penguins with 30% data for testing and 70% for training and keeping n=5 by following attributes,\n",
    "#then accuracy for each tril is\n",
    "\n",
    "#culmen_length_mm=73.27%\n",
    "#culmen_depth_mm=76.24%\n",
    "#flipper_length_mm=80.2%\n",
    "#body_mass_g=72.28%\n",
    "'''\n",
    "CL+CD=97.03%\n",
    "CL+FL=97.03%\n",
    "CL+BM=78.22%\n",
    "CD+FL=82.18%\n",
    "CD+BM=70.3%\n",
    "FL+BM=73.27%\n",
    "CL+CD+FL=97.03%\n",
    "CL+CD+BM=78.22%\n",
    "CL+FL+BM=78.22%\n",
    "CD+FL+BM=74.26%\n",
    "CL+CD+FL+BM=79.21%\n",
    "'''\n",
    "#Where \n",
    "'''\n",
    "CL=cumen_length_mm\n",
    "CD=cumen_depth_mm\n",
    "FL=flipper_length_mm\n",
    "BM=body_mass_g\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCL+CD=97.03%\\nCL+FL=97.03%\\nCL+BM=78.22%\\nCD+FL=82.18%\\nCD+BM=70.3%\\nFL+BM=73.27%\\nCL+CD+FL=97.03%\\nCL+CD+BM=78.22%\\nCL+FL+BM=78.22%\\nCD+FL+BM=74.26%\\nCL+CD+FL+BM=\\n'"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we classify the penguins with 30% data for testing and 70% for training and keeping n=7 by following attributes,\n",
    "#then accuracy for each tril is\n",
    "\n",
    "#culmen_length_mm=73.27%\n",
    "#culmen_depth_mm=76.24%\n",
    "#flipper_length_mm=80.2%\n",
    "#body_mass_g=72.28%\n",
    "'''\n",
    "CL+CD=97.03%\n",
    "CL+FL=97.03%\n",
    "CL+BM=78.22%\n",
    "CD+FL=82.18%\n",
    "CD+BM=70.3%\n",
    "FL+BM=73.27%\n",
    "CL+CD+FL=97.03%\n",
    "CL+CD+BM=78.22%\n",
    "CL+FL+BM=78.22%\n",
    "CD+FL+BM=74.26%\n",
    "CL+CD+FL+BM=79.21%\n",
    "'''\n",
    "#Where \n",
    "'''\n",
    "CL=cumen_length_mm\n",
    "CD=cumen_depth_mm\n",
    "FL=flipper_length_mm\n",
    "BM=body_mass_g\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
